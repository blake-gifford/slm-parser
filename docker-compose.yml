services:
  app:
    build: .
    env_file: 'backend.env'
    ports:
      - "8501:8501"
    depends_on:
      - llm
      
  llm:
    provider:
      type: model
      options:
        model: ai/llama3.2